This project implements an autoencoder using a neural network (NN) class in Python, which can be initialized with any number of hidden layers, neurons per layer, and activation functions.. The autoencoder is trained on a subset of the MNIST dataset, specifically on images of the digit '2'. The purpose of this autoencoder is to compress the input data to a lower-dimensional representation and then reconstruct it back to its original form. The network architecture includes multiple hidden layers, and the training process uses backpropagation to minimize the reconstruction error. The results are visualized by comparing the original and reconstructed images.
